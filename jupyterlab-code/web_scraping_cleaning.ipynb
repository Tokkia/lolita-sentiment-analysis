{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20701508",
   "metadata": {},
   "source": [
    "### Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72fbbbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e2dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get reviews from a specific page\n",
    "def get_reviews(page_url, headers):\n",
    "    response = requests.get(page_url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        return None\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    reviews = soup.find_all('article', class_='ReviewCard')\n",
    "    return reviews\n",
    "\n",
    "# Initial URL\n",
    "url = \"https://www.goodreads.com/book/show/123372185-lolita-by-vladimir-nabokov\"\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'} \n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "# Initialize the review dictionary\n",
    "review_dict = {'reviews':[], 'rating': []}\n",
    "\n",
    "# Simulate pagination\n",
    "for page_num in range(1, 200):  # Adjust the range based on how many pages you want to scrape\n",
    "    page_url = f\"{url}?page={page_num}\"  # Modify this if the pagination parameter is different\n",
    "    reviews = get_reviews(page_url, headers)\n",
    "    \n",
    "    if not reviews:\n",
    "        break\n",
    "    \n",
    "    for review in reviews:\n",
    "        # Find the review text \n",
    "        review_content = review.find('section', class_='ReviewText__content')\n",
    "        if review_content:\n",
    "            review_text = review_content.get_text(strip=True)\n",
    "            review_dict['reviews'].append(review_text)\n",
    "        else:\n",
    "            review_dict['reviews'].append(None)\n",
    "        \n",
    "        # Find the rating \n",
    "        rating_element = review.find('span', class_=\"RatingStars RatingStars__small\")\n",
    "        if rating_element:\n",
    "            rating = rating_element.get('aria-label')\n",
    "            review_dict['rating'].append(rating)\n",
    "        else:\n",
    "            review_dict['rating'].append(None)\n",
    "    \n",
    "    print(f\"Scraped page {page_num}\")\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame(review_dict)\n",
    "print(df.head())\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('scraped.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2d282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5970, 2)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d128e9",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bea2e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Between the CoversAfter re-reading \"Lolita\", I...</td>\n",
       "      <td>Rating 5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nymph. Nymphet. Nymphetiquette. Nymphology. Ny...</td>\n",
       "      <td>Rating 5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Now, this is going to be embarrassing to admit...</td>\n",
       "      <td>Rating 5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I wasn't even going to write a review ofLolita...</td>\n",
       "      <td>Rating 4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when i first read this book, i hated every sec...</td>\n",
       "      <td>Rating 4 out of 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews             rating\n",
       "0  Between the CoversAfter re-reading \"Lolita\", I...  Rating 5 out of 5\n",
       "1  Nymph. Nymphet. Nymphetiquette. Nymphology. Ny...  Rating 5 out of 5\n",
       "2  Now, this is going to be embarrassing to admit...  Rating 5 out of 5\n",
       "3  I wasn't even going to write a review ofLolita...  Rating 4 out of 5\n",
       "4  when i first read this book, i hated every sec...  Rating 4 out of 5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "df_1 = pd.read_csv(\"scraped.csv\")\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc5d4295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out non-English reviews\n",
    "df_2 = df_1.copy()\n",
    "\n",
    "from langdetect import detect\n",
    "\n",
    "def is_eng(text):\n",
    "    return detect(text) == 'en'\n",
    "\n",
    "# add col: eng = True if english\n",
    "df_2['eng'] = df_2['reviews'].apply(is_eng)\n",
    "# filter out eng = False & remove eng column\n",
    "df_2 = df_2[df_2['eng']==True].iloc[:, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c25d60ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5211, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc015901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Between the CoversAfter re-reading \"Lolita\", I...</td>\n",
       "      <td>Rating 5 out of 5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nymph. Nymphet. Nymphetiquette. Nymphology. Ny...</td>\n",
       "      <td>Rating 5 out of 5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Now, this is going to be embarrassing to admit...</td>\n",
       "      <td>Rating 5 out of 5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I wasn't even going to write a review ofLolita...</td>\n",
       "      <td>Rating 4 out of 5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when i first read this book, i hated every sec...</td>\n",
       "      <td>Rating 4 out of 5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews             rating   eng\n",
       "0  Between the CoversAfter re-reading \"Lolita\", I...  Rating 5 out of 5  True\n",
       "1  Nymph. Nymphet. Nymphetiquette. Nymphology. Ny...  Rating 5 out of 5  True\n",
       "2  Now, this is going to be embarrassing to admit...  Rating 5 out of 5  True\n",
       "3  I wasn't even going to write a review ofLolita...  Rating 4 out of 5  True\n",
       "4  when i first read this book, i hated every sec...  Rating 4 out of 5  True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7f814a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize & lemmatize text\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# load stopwords and words corpus\n",
    "stop_words = set(stopwords.words('english'))\n",
    "english_words = set(words.words())\n",
    "\n",
    "# initialize  lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to clean review text\n",
    "def clean_review_text(review_text):\n",
    "    # tokenize reviews into words, remove stop words, and lemmatize\n",
    "    # the words part removes words that were vectorized wrong\n",
    "    cleaned_words = [lemmatizer.lemmatize(token) for token in nltk.word_tokenize(review_text.lower()) if token not in stop_words and token in english_words]\n",
    "    \n",
    "    # reconstruct the cleaned review text\n",
    "    cleaned_review_text = ' '.join(cleaned_words)\n",
    "    \n",
    "    return cleaned_review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d95247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_2.copy()\n",
    "# apply function to text\n",
    "df_3['reviews'] = df_3['reviews'].apply(clean_review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "906aef45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5211, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3 = df_3.iloc[:, :2]\n",
    "df_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1be41ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>local bookseller ever read firmly going either...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nymph nymphet never think year old way stain b...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>going embarrassing know reading enjoying book ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>even going write review finishing honestly man...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first read book every second pride reader dist...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  rating\n",
       "0  local bookseller ever read firmly going either...     5.0\n",
       "1  nymph nymphet never think year old way stain b...     5.0\n",
       "2  going embarrassing know reading enjoying book ...     5.0\n",
       "3  even going write review finishing honestly man...     4.0\n",
       "4  first read book every second pride reader dist...     4.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert ratings var to numerical\n",
    "\n",
    "ratings_dict = {\"Rating 5 out of 5\": 5, \"Rating 4 out of 5\": 4, \"Rating 3 out of 5\": 3,\n",
    "                \"Rating 2 out of 5\": 2, \"Rating 1 out of 5\": 1}\n",
    "\n",
    "df_3['rating']=df_3['rating'].replace(ratings_dict)\n",
    "\n",
    "df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11fb7c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5211, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e31b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.to_csv(\"cleaned_goodreads_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c478a6ed",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "545017d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5211, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "df = pd.read_csv(\"cleaned_goodreads_reviews.csv\",index_col=0)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91088aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>ability</th>\n",
       "      <th>abject</th>\n",
       "      <th>able</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>abortion</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absorbed</th>\n",
       "      <th>...</th>\n",
       "      <th>yearlong</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>youthful</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024681</td>\n",
       "      <td>0.024681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032448</td>\n",
       "      <td>0.020680</td>\n",
       "      <td>0.073342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057057</td>\n",
       "      <td>0.079048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111367</td>\n",
       "      <td>0.070977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2689 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aback   abandon  ability  abject      able  abnormal  abortion  \\\n",
       "0  0.024681  0.024681      0.0     0.0  0.016804       0.0       0.0   \n",
       "1  0.000000  0.000000      0.0     0.0  0.023182       0.0       0.0   \n",
       "2  0.000000  0.000000      0.0     0.0  0.000000       0.0       0.0   \n",
       "3  0.000000  0.000000      0.0     0.0  0.000000       0.0       0.0   \n",
       "4  0.000000  0.000000      0.0     0.0  0.000000       0.0       0.0   \n",
       "\n",
       "   absolute  absolutely  absorbed  ...  yearlong       yes       yet  york  \\\n",
       "0  0.000000         0.0  0.000000  ...       0.0  0.000000  0.000000   0.0   \n",
       "1  0.028529         0.0  0.000000  ...       0.0  0.057057  0.079048   0.0   \n",
       "2  0.000000         0.0  0.084708  ...       0.0  0.000000  0.000000   0.0   \n",
       "3  0.000000         0.0  0.000000  ...       0.0  0.000000  0.000000   0.0   \n",
       "4  0.000000         0.0  0.000000  ...       0.0  0.000000  0.000000   0.0   \n",
       "\n",
       "      young   younger     youth  youthful  zero      zone  \n",
       "0  0.032448  0.020680  0.073342       0.0   0.0  0.024681  \n",
       "1  0.044763  0.000000  0.000000       0.0   0.0  0.000000  \n",
       "2  0.111367  0.070977  0.000000       0.0   0.0  0.000000  \n",
       "3  0.000000  0.000000  0.000000       0.0   0.0  0.000000  \n",
       "4  0.000000  0.000000  0.000000       0.0   0.0  0.000000  \n",
       "\n",
       "[5 rows x 2689 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize vectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "# transform each review into row of tf-idf'ed features\n",
    "matrix = vectorizer.fit_transform(df['reviews'])\n",
    "# extract list of features\n",
    "features = vectorizer.get_feature_names_out()\n",
    "\n",
    "# combine in dataframe & create csv\n",
    "df_tfidf = pd.DataFrame(matrix.toarray(), columns=features)\n",
    "df_tfidf.to_csv(\"all_tfidf.csv\")\n",
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be703509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5211, 2689)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
